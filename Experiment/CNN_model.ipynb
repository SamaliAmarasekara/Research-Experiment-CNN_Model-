{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split ################################################this is wanted but didnt work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=1\n",
    "num_epoch=20\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "labels_name={'circle':1,'box':0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the images of dataset-.ipynb_checkpoints\n",
      "\n",
      "Loading the images of dataset-box\n",
      "\n",
      "Loading the images of dataset-circle\n",
      "\n",
      "Loading the images of dataset-test\n",
      "\n",
      "(32, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "img_data_list=[]\n",
    "labels_list = []###\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loading the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    #label = labels_name[dataset]###\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(128,128))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        #labels_list.append(label)###\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samali\\Anaconda3\\envs\\machineLearning\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
    "\t\tprint (img_data.shape)\n",
    "\telse:\n",
    "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
    "\t\tprint (img_data.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data=np.rollaxis(img_data,3,1)\n",
    "\t\tprint (img_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-.ipynb_checkpoints\n",
      "\n",
      "Loaded the images of dataset-box\n",
      "\n",
      "Loaded the images of dataset-circle\n",
      "\n",
      "Loaded the images of dataset-test\n",
      "\n",
      "(32, 16384)\n",
      "(32, 16384)\n",
      "7.916242e-09\n",
      "1.0\n",
      "[-3.7252903e-09  3.7252903e-09  1.8626451e-09 ... -1.8626451e-08\n",
      "  5.5879354e-09  1.3038516e-08]\n",
      "[1.0000001  0.9999999  1.0000001  ... 1.0000001  0.99999994 1.        ]\n",
      "(32, 128, 128, 1)\n",
      "(32, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samali\\Anaconda3\\envs\\machineLearning\\lib\\site-packages\\sklearn\\preprocessing\\data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "USE_SKLEARN_PREPROCESSING=True\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "\t# using sklearn for preprocessing\n",
    "\tfrom sklearn import preprocessing\n",
    "\t\n",
    "\tdef image_to_feature_vector(image, size=(128, 128)):\n",
    "\t\t# resize the image to a fixed size, then flatten the image into\n",
    "\t\t# a list of raw pixel intensities\n",
    "\t\treturn cv2.resize(image, size).flatten()\n",
    "\t\n",
    "\timg_data_list=[]\n",
    "\tfor dataset in data_dir_list:\n",
    "\t\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\t\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\t\tfor img in img_list:\n",
    "\t\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tinput_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
    "\t\t\timg_data_list.append(input_img_flatten)\n",
    "\t\n",
    "\timg_data = np.array(img_data_list)\n",
    "\timg_data = img_data.astype('float32')\n",
    "\tprint (img_data.shape)\n",
    "\timg_data_scaled = preprocessing.scale(img_data)\n",
    "\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\tprint (np.mean(img_data_scaled))\n",
    "\tprint (np.std(img_data_scaled))\n",
    "\t\n",
    "\tprint (img_data_scaled.mean(axis=0))\n",
    "\tprint (img_data_scaled.std(axis=0))\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "        \n",
    "if USE_SKLEARN_PREPROCESSING: \n",
    "    img_data = img_data_scaled\n",
    "    \n",
    "img_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning labels\n",
    "\n",
    "#define the num of classes\n",
    "num_classes = 2\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "#labels[0:14]=0\n",
    "#labels[14:31]=1\n",
    "\n",
    "\n",
    "#names = ['circle','box']\n",
    "#convert class labels\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#shuffle\n",
    "x,y = shuffle(img_data, Y, random_state=2)\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Defining the model\n",
    "\n",
    "input_shape=img_data[0].shape\n",
    "\n",
    "\t\t\t\t\t\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "\n",
    "# Viewing model_configuration\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Training\n",
    "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "#hist = model.fit(X_train, y_train, batch_size=32, nb_epoch=20,verbose=1, validation_split=0.2)\n",
    "\n",
    "# Training with callbacks\n",
    "from keras import callbacks\n",
    "\n",
    "filename='model_train_new.csv'\n",
    "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=20, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test),callbacks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Evaluating the model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[0:1]\n",
    "print (test_image.shape)\n",
    "\n",
    "print(model.predict(test_image))\n",
    "print(model.predict_classes(test_image))\n",
    "print(y_test[0:1])\n",
    "\n",
    "# Testing a new image\n",
    "test_image = cv2.imread('data/test/test1.jpg')\n",
    "test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "test_image=cv2.resize(test_image,(128,128))\n",
    "test_image = np.array(test_image)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "print (test_image.shape)\n",
    "   \n",
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=3) \n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\ttest_image=np.rollaxis(test_image,2,0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "print((model.predict(test_image)))\n",
    "print((model.predict_classes(test_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
